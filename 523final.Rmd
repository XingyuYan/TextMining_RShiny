---
title: "523Final"
author: Group 9
output: html_document
---

## Text mining

The text mining part is to input the file, to clean it up and to output a table where each word and its appearing frequency are listed. The cleaning method is using both stringr and gsub, where we get rid of all punctuations, numbers, and simple letters. Besides, as we don't want the stop words, such as "I", "and", and "the", we delete them as well. At the end, we output a dataframe which contains two columns: keys and values.

```{r}
library(purrr)
library(magrittr)
library(stringr)
library(dplyr)
library(tm)

textmining = function(file)
{
  # testing file : "/data/Shakespeare/hamlet.txt"
  data = readLines(file) %>% as.list()
  
  # Map step
  map_count_words = function(val)
  {
    stopifnot(length(val) == 1)
    
    # delete punctuations and numbers
    val = gsub("[[:punct:]]", " ", val)
    val = gsub("[[:digit:]]+", " ", val)
    # clean it up
    val %>%
      tolower() %>%
      str_split(" ") %>%
      {.[[1]]} %>%
      str_trim() %>%
      .[. != ""] %>%
      .[! . %in% stopwords("en")] %>%
      table() %>% 
      as.list()
  }
  
  res_map = lapply(data, map_count_words) %>% flatten()
  
  # Shuffle step
  keys = names(res_map) %>% unique()
  res_shuf = lapply(keys, function(key) unlist(res_map[names(res_map) == key]) %>% setNames(NULL)) %>% setNames(keys)
  
  # Reduce step
  reduce_func = sum
  res_red = lapply(res_shuf, reduce_func)
  
  tbl = data_frame(keys = names(res_red), 
             values = unlist(res_red)) %>% 
             arrange(desc(values))
  
  # delete the single letters
  tbl1 = tbl
  index = c()
  for(i in 1:nrow(tbl1[,1]))
  {
    if(nchar(tbl1[i,1][[1]])==1)
    {
      index = c(index, i)
    }
  }
  tbl1 = tbl1[-index,]
  
  tbl2 = tbl1 %>% arrange(desc(values))
  return(tbl2)
}
```


## Displaying

```{r}


```


## Shiny

```{r}


```